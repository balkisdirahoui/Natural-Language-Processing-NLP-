{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP sur l'analyse de phrase par HMM\n",
    "\n",
    "Le but de ce tp est de reprendre les modèles développés en MAPSI pour les appliquer sur un problème d'analyse de séqences.\n",
    "Nous allons travailler sur le Part-Of-Speech (POS) et optionnellement sur le chunking (le fait de regrouper les groupes nominaux et verbaux dans les phrases). Les données sont issus de CONLL 2000 [https://www.clips.uantwerpen.be/conll2000/chunking/]\n",
    "\n",
    "Les données sont disponibles en petite quantité (pour comprendre le fonctionnement des outils) puis en grande quantité pour effecter des expériences fiables.\n",
    "\n",
    "Le but du TP est de prendre en main les données sur une tâche simple (POS/Chunking) puis de donner des perforances sur la tâche de NER. Cette dernière partie est décrite dans l'avant dernière boite de ce TME, elle constitue cependant la plus grosse partie du travail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données POS/Chunking\n",
    "# Cette fonction doit être ré-écrite en v2 pour charger les données NER de connl 2003\n",
    "def load(filename):\n",
    "    listeDoc = list()\n",
    "    with open(filename, \"r\") as f:\n",
    "        doc = list()\n",
    "        for ligne in f:\n",
    "            #print \"l : \",len(ligne),\" \",ligne\n",
    "            if len(ligne) < 2: # fin de doc\n",
    "                listeDoc.append(doc)\n",
    "                doc = list()\n",
    "                continue\n",
    "            mots = ligne.replace(\"\\n\",\"\").split(\" \")\n",
    "            doc.append((mots[0],mots[1])) # mettre mots[2] à la place de mots[1] pour le chuncking\n",
    "    return listeDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== chargement ============\n",
    "# sous ensemble du corpus => Idéal pour les premiers test\n",
    "filename = \"ressources/conll2000/chtrain.txt\" \n",
    "filenameT = \"ressources/conll2000/chtest.txt\" \n",
    "\n",
    "# corpus plus gros => Pour valider les perf.\n",
    "# filename = \"ressources/conll2000/train.txt\" \n",
    "# filenameT = \"ressources/conll2000/test.txt\" \n",
    "\n",
    "alldocs = load(filename)\n",
    "alldocsT = load(filenameT)\n",
    "\n",
    "print(len(alldocs),\" docs read\")\n",
    "print(len(alldocsT),\" docs (T) read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alldocs[0])\n",
    "print(alldocsT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un modèle de référence POS à base de dictionnaire\n",
    "\n",
    "```mot => étiquette``` sans prise en compte de la séquence. Il faudra comparer tout résultat plus lourd à cette référence.\n",
    "\n",
    "On ne s'intéresse qu'à l'étiquette POS, sachant que le corpus a été décomposé en ```(mot, POS, Chunk)```.\n",
    "\n",
    "1. Création du dictionnaire d'équivalence à partir du *train*\n",
    "1. Mesure de l'efficacité en *test*\n",
    "\n",
    "**Note** certains mots du test sont évidemment inconnus... Sur le plan technique, il faut remplacer:\n",
    "```\n",
    "# remplacer\n",
    "dico[cle] # qui plante en cas de clé inconnue\n",
    "# par \n",
    "dico.get(cle, valeurParDefaut)\n",
    "```\n",
    "Sur le plan linguistique, on peut affecter la classe majoritaire à tous les mots inconnus, on aura alors une référence plus forte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du dictionnaire \n",
    "\n",
    "dico = dict()\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation des performances en test (et en apprentissage)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1433 bonne réponses en test sur 1896\n",
    "\n",
    "(1527 avec 'NN' par défaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de séquence\n",
    "\n",
    "Je vous donne la correction des TME MAPSI: un apprentissage de HMM et une fonction viterbi. Vous allez devoir l'appliquer sur les données.\n",
    "Je vous demande seulement de comprendre la signification du paramètre ```eps``` dans l'algorithme HMM. C'est un paramètre important: jouez avec, touver la bonne valeur pour cette application.\n",
    "\n",
    "Il faut mettre en forme les données pour avoir des indices associés aux mots, sinon, on n'arrivera pas à faire des HMM... Tout le code pour la mise en forme est fourni ci-dessous.\n",
    "```\n",
    " The cat is in the garden => 1 2 3 4 1 5\n",
    "```\n",
    "\n",
    "Pour une construction facilité du dictionnaire, on utilisera la méthode ```setdefault```\n",
    "\n",
    "Afin de produire des analyses qualitative, vous devez malgré tout comprendre le fonctionnement des dictionnaires pour retrouver les mots qui correspondent aux indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allx: liste de séquences d'observations\n",
    "# allq: liste de séquences d'états\n",
    "# N: nb états\n",
    "# K: nb observation\n",
    "\n",
    "def learnHMM(allx, allq, N, K, initTo1=True):\n",
    "    if initTo1:\n",
    "        eps = 1e-3 # vous pouvez jouer avec ce paramètre de régularisation\n",
    "        A = np.ones((N,N))*eps\n",
    "        B = np.ones((N,K))*eps\n",
    "        Pi = np.ones(N)*eps\n",
    "    else:\n",
    "        A = np.zeros((N,N))\n",
    "        B = np.zeros((N,K))\n",
    "        Pi = np.zeros(N)\n",
    "    for x,q in zip(allx,allq):\n",
    "        Pi[int(q[0])] += 1\n",
    "        for i in range(len(q)-1):\n",
    "            A[int(q[i]),int(q[i+1])] += 1\n",
    "            B[int(q[i]),int(x[i])] += 1\n",
    "        B[int(q[-1]),int(x[-1])] += 1 # derniere transition\n",
    "    A = A/np.maximum(A.sum(1).reshape(N,1),1) # normalisation\n",
    "    B = B/np.maximum(B.sum(1).reshape(N,1),1) # normalisation\n",
    "    Pi = Pi/Pi.sum()\n",
    "    return Pi , A, B\n",
    "\n",
    "def viterbi(x,Pi,A,B):\n",
    "    T = len(x)\n",
    "    N = len(Pi)\n",
    "    logA = np.log(A)\n",
    "    logB = np.log(B)\n",
    "    logdelta = np.zeros((N,T))\n",
    "    psi = np.zeros((N,T), dtype=int)\n",
    "    S = np.zeros(T)\n",
    "    logdelta[:,0] = np.log(Pi) + logB[:,int(x[0])]\n",
    "    #forward\n",
    "    for t in range(1,T):\n",
    "        logdelta[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).max(0) + logB[:,int(x[t])]\n",
    "        psi[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).argmax(0)\n",
    "    # backward\n",
    "    logp = logdelta[:,-1].max()\n",
    "    S[T-1] = logdelta[:,-1].argmax()\n",
    "    for i in range(2,T+1):\n",
    "        S[int(T-i)] = psi[int(S[int(T-i+1)]),int(T-i+1)]\n",
    "    return S, logp #, delta, psi\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldocs etant issu du chargement des données\n",
    "# la mise en forme des données est fournie ici\n",
    "# afin de produire des analyses qualitative, vous devez malgré tout comprendre le fonctionnement des dictionnaires\n",
    "\n",
    "buf = [[m for m,pos in d ] for d in alldocs]\n",
    "mots = []\n",
    "[mots.extend(b) for b in buf]\n",
    "mots = np.unique(np.array(mots))\n",
    "nMots = len(mots)+1 # mot inconnu\n",
    "\n",
    "mots2ind = dict(zip(mots,range(len(mots))))\n",
    "mots2ind[\"UUUUUUUU\"] = len(mots)\n",
    "\n",
    "buf2 = [[pos for m,pos in d ] for d in alldocs]\n",
    "cles = []\n",
    "[cles.extend(b) for b in buf2]\n",
    "cles = np.unique(np.array(cles))\n",
    "cles2ind = dict(zip(cles,range(len(cles))))\n",
    "\n",
    "nCles = len(cles)\n",
    "\n",
    "print(nMots,nCles,\" in the dictionary\")\n",
    "\n",
    "# mise en forme des données\n",
    "allx  = [[mots2ind[m] for m,pos in d] for d in alldocs]\n",
    "allxT = [[mots2ind.setdefault(m,len(mots)) for m,pos in d] for d in alldocsT]\n",
    "\n",
    "allq  = [[cles2ind[pos] for m,pos in d] for d in alldocs]\n",
    "allqT = [[cles2ind.setdefault(pos,len(cles)) for m,pos in d] for d in alldocsT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage du premier doc:\n",
    "print(allx[0])\n",
    "print(allq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application des HMM sur ces données\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# décodage des séquences de test & calcul de performances\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : 1564 en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse qualitative:\n",
    "\n",
    "- A l'aide d'un imshow sur les paramètres (ou d'un argsort), montrer quels sont les enchaînements probables d'étiquettes.\n",
    "\n",
    "- Visualiser aussi les matrices de confusion pour comprendre ce qui est difficile dans cette tâche\n",
    "\n",
    "- Extraire les exemples qui sont effectivement corrigés par viterbi\n",
    "\n",
    "- Le fait de traiter le texte (enlever les majuscules, les ponctuations, etc) fait-il varier les performances (**ATTENTION**, ça fait varier le nombre de mots)\n",
    "\n",
    "Penser à sauvegarder quasi-systématiquement les figures que vous produisez. Vous privilégierez le format pdf vectoriel. Le repertoire ```out``` est là pour stocker toutes les sorties. Vous devez donc obtenir quelque chose de la forme:\n",
    "```\n",
    "plt.figure() # nouvelle figure\n",
    "...\n",
    "plt.savefig(\"out/ma_figure.pdf\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test d'outils plus avancés\n",
    "\n",
    "1. On propose de faire des tests avec CRFTagger\n",
    "\n",
    "[https://tedboy.github.io/nlps/generated/generated/nltk.CRFTagger.html]\n",
    "\n",
    "1. PerceptronTagger de nltk\n",
    "\n",
    "1. En dehors de python, vous pouvez facilement utiliser le vénérable TreeTagger qui fonctionne toujours bien (mais pas forcément dans le même référenciel d'étiquetage:\n",
    "[http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/]\n",
    "Il y a même un wrapper python en bas de la page pour intégrer ça dans votre code.\n",
    "Ce tagger a l'avantage d'avoir des modules pour le français.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut parfois:\n",
    "# !pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.crf           import CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = CRFTagger()\n",
    "tagger.train(alldocs, 'out/crf.model') # apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesure de la performance (à aller chercher dans la documentation)\n",
    "# le même travail qualitatif que précédemment est possible (et souhaitable !)...\n",
    "# ... Il est aussi très simple si votre code est mis dans des fonctions\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1720 bonnes réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron\n",
    "\n",
    "from nltk.tag.perceptron    import PerceptronTagger\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.train(alldocs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: 1737 bonnes réponses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Et sur d'autres applications?\n",
    "\n",
    "Vous pouvez directement tester toutes les méthodes précédentes sur le chunking en changeant juste la fonction de chargement des données.\n",
    "Le codage des séquences est très intéressant avec des balises B(egin)/I(n).\n",
    "\n",
    "Du point de vue industriel, une des tâches les plus importantes est la détection d'entités nommées. Pour attaquer facilement la tâche NER, le dataset CoLNN 2003 est parfait (les datasets correspondant aux années suivantes sont corrects également).\n",
    "Le codage des séquences est un peu plus compliqué pour le NER.\n",
    "\n",
    "**Note 1**  Il faut faire attention dans cette tâche à ne calculer les taux de bonne classification que sur les entités et pas sur le tag *O=out*... On peut ensuite calculer une métrique à part pour les faux positifs.\n",
    "\n",
    "**Note 2** Il créer une nouvelle version du lecteur de données, ce qui constitue un très bon exercice.\n",
    "\n",
    "**Note 3** Ce jeu de données est encore largement utilisé en recherche: ce travail peut donc figurer dans votre CV :)\n",
    "\n",
    "**Note 4** Afin de conserver un code plus facile à lire, il peut être utile de traiter cette question dans un nouveau notebook.\n",
    "\n",
    "Lien vers le site officiel (qui ne contient pas les données!): [https://www.clips.uantwerpen.be/conll2003/ner/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outils de l'état de l'art\n",
    "\n",
    "Pour aller plus loin, ça vaut le coup de refaire les expériences avec des outils reconnus pour le leurs qualités:\n",
    "https://github.com/stanfordnlp/stanza/\n",
    "\n",
    "On dérive vite vers des réseaux de neurones... Qui relèvent plutot du M2 DAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
