{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des techniques de clustering\n",
    "\n",
    "Le but de ce tp est de faire face Ã  la problÃ©matique: \n",
    "<center style=\"color:red\" >  Voici XXX documents -bruts, non Ã©tiquetÃ©s-... Comment les valoriser? Les exploiter? Les comprendre? Les rÃ©sumer? </center>\n",
    "\n",
    "Nous avons vu dans les sÃ©ances prÃ©cÃ©dentes comment reprÃ©senter les donnÃ©es textuelles sous forme de sacs de mots:\n",
    "$$X = \n",
    "\t\\begin{matrix} \n",
    "\t & \\textbf{t}_j \\\\\n",
    "\t & \\downarrow \\\\\n",
    "\t\\textbf{d}_i \\rightarrow &\n",
    "\t\\begin{pmatrix} \n",
    "\tx_{1,1} & \\dots & x_{1,D} \\\\\n",
    "\t\\vdots & \\ddots & \\vdots \\\\\n",
    "\tx_{N,1} & \\dots & x_{N,D} \\\\\n",
    "\t\\end{pmatrix}\n",
    "\t\\end{matrix}\n",
    "\t$$\n",
    "\n",
    "A partir de cette reprÃ©sentation, les questions qui se posent sont les suivantes:\n",
    "1. Quel algorithme de clustiering choisir?\n",
    "    - K-means, LSA, pLSA, LDA\n",
    "1. Quels rÃ©sultats attendre?\n",
    "    - qualitÃ©, bruit, exploitabilitÃ© immÃ©diate etc...\n",
    "1. Quelles analyses qualitatives effectuer pour comprendre les groupes?\n",
    "1. Comment boucler, itÃ©rer pour amÃ©liorer la qualitÃ© du processus?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des donnÃ©es\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 500)\n",
      "70.5516174650875\n"
     ]
    }
   ],
   "source": [
    "# conversion BoW + tf-idf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer() # TfidfVectorizer(max_features=500)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "print(vectors.shape)\n",
    "\n",
    "# mesure de la sparsitÃ© = 157 mots actif par document sur 130000 !!\n",
    "print(vectors.nnz / float(vectors.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(54, 'anything'), (269, 'maybe'), (100, 'case'), (132, 'doesn'), (152, 'everything'), (46, 'american'), (287, 'nasa'), (444, 'type'), (66, 'available'), (384, 'show')]\n"
     ]
    }
   ],
   "source": [
    "# retrouver les mots\n",
    "print([(i,vectorizer.get_feature_names()[i]) \\\n",
    "       for i in np.random.randint(vectors.shape[1], size=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  4  4  1 14 16 13  3  2  4]\n",
      "['rec.autos', 'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics', 'sci.space', 'talk.politics.guns', 'sci.med', 'comp.sys.ibm.pc.hardware', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware']\n"
     ]
    }
   ],
   "source": [
    "# gestion des Ã©tiquettes (pour l'Ã©valuation seulemnet en non-supervisÃ©)\n",
    "Y = newsgroups_train.target\n",
    "print(Y[:10]) # numÃ©rique\n",
    "print([newsgroups_train.target_names[i] for i in Y[:10]]) # vraie classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests prÃ©liminaires\n",
    "\n",
    "CommenÃ§ons par le commencement: tout problÃ¨me non-supervisÃ© (ou presque) doit Ãªtre analysÃ© en premier lieu avec les $k$-means!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Algo => risque de prendre du temps si le vocabulaire n'a pas Ã©tÃ© rÃ©duit !!\n",
    "# Note: on dirait que l'algo transforme les donnÃ©es en dense vector=> catastrophe pour nous !!!\n",
    "# => limitation du nombre d'itÃ©ration arbitraire + limitation du vocabulaire\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=0, max_iter=10).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse\n",
    "\n",
    "# recupÃ©ration des proto:\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "# mots les plus importants par cluster => TODO\n",
    "# version print / version word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites\n",
    "\n",
    "- Limites liÃ©es Ã  la description\n",
    "    - trop de mots\n",
    "    - trop de mots frÃ©quents qui dÃ©routent l'algorithme\n",
    "    - ...\n",
    "- Limites liÃ©es Ã  l'algorithme\n",
    "    - distance euclidienne absurde\n",
    "\n",
    "Les limites algorithmiques vont Ãªtre rÃ©solues en changeant d'algorithme... Les limites de reprÃ©sentation des donnÃ©es seront rÃ©solues par votre capacitÃ© en ingÃ©nierie.\n",
    "\n",
    "\n",
    "Algorithmes Ã  tester:\n",
    "- LSA\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD\n",
    "- LDA\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "**Note:** pour des tests rapides, il est plus simple de rester dans le cadre de scikit-learn... NÃ©anmoins, dans un milieu industriel, il faudrait exploiter des outils plus efficaces comme ceux prÃ©sents dans la librairie ```gensim```. Si vous vous sentez Ã  l'aise avec la donnÃ©e textuelles, allez directement vers ces outils:\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des performances\n",
    "\n",
    "Les performances sont trÃ¨s dures Ã  Ã©valuer en clustering... Ce qui explique que cette Ã©valuation est souvent, au moins partiellement, qualitative (=Ã©tudiÃ©e Ã  l'oeil, sur des exemples ou des paramÃ¨tres). \n",
    "Afin d'Ã©viter de faire n'importe quoi, il faut aussi rÃ©flÃ©chir Ã  des mÃ©triques quantitatives.\n",
    "\n",
    "### Qualitatif\n",
    "\n",
    "Analyser le vocabulaire des diffÃ©rents clusters\n",
    "1. En terme de mots les plus frÃ©quents, les plus probables ou de dimensions des vecteurs propres les plus fortes.\n",
    "1. En terme de mots discriminants\n",
    "    - construction de critÃ¨re de contraste (type odd's ratio) entre la prÃ©sence dans une classe et prÃ©sence dans les autres classe\n",
    "1. Affichage \n",
    "    - des 10 ou 20 mots critiques de chaque classe ```print```\n",
    "    - sous la forme de word cloud\n",
    "    - affichage interactif avancÃ©: http://www.kennyshirley.com/LDAvis/\n",
    "        - pour une version intÃ©grable dans un notebook: https://github.com/bmabey/pyLDAvis\n",
    "        - merci de l'utiliser **aprÃ¨s avoir compris le principe de rÃ©duction de la dimensionalitÃ© pour les clusters**\n",
    "    \n",
    "### Quantitatif\n",
    "\n",
    "Pour donner des chiffres, il faut des Ã©tiquettes. C'est rarement le cas sur des jeux de donnÃ©es industriels... Mais c'est bon dans un cadre acadÃ©mique comme 20 newsgroups!\n",
    "\n",
    "**ProblÃ¨me:** Comme nos algorithmes sont non supervisÃ©s, les sorties (bien que catÃ©gorielles) ne sont pas alignÃ©es avec l'encodage des Ã©tiquettes du jeu de donnÃ©es. Il faut trouver des astuces.\n",
    "\n",
    "1. Etude basique sur la taille des clusters\n",
    "    - est ce qu'une classe n'a pas tout attrapÃ©?\n",
    "1. PuretÃ© = extraction de la classe majoritaire dans un cluster + calcul de la puretÃ© du cluster\n",
    "    - 1 score par cluster par dÃ©faut\n",
    "    - agrÃ©gation par somme pondÃ©rÃ©e sur la taille des clusters\n",
    "1. Indice de Rand  https://fr.wikipedia.org/wiki/Indice_de_Rand\n",
    "1. MÃ©trique adaptÃ©e Ã  une hypothÃ¨se spÃ©cifique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vers une version plus Ã©voluÃ©e des algorithmes\n",
    "\n",
    "1. Si l'un des clusters attirÃ© toutes les donnÃ©es: Ãªtes-vous capable de supprimer ce cluster et de simplement rÃ©partir les Ã©chantillons dans les autres catÃ©gories?\n",
    "\n",
    "1. Si vous avez une idÃ©e vague des thÃ©matiques que vous souhaitez voir isolÃ©es... \n",
    "    - trouver 10 mots dans chaque catÃ©gories\n",
    "    - biaiser l'initialisation pour attirer ces classes\n",
    "\n",
    "1. Si vous mettez un utilisateur dans la boucle\n",
    "    - passer en mode supervisÃ© multiclasse et exploiter les feedbacks de l'utilisateur pour forcer le passage d'un document dans la classe d'Ã  cotÃ© \n",
    "        - Naive Bayes, SVM ou autre...\n",
    "    - rÃ©flÃ©chir Ã  une approche active qui sÃ©lectionne les documents les plus intÃ©ressants Ã  montrer Ã  l'utilisateur pour lui demander un Ã©tiquetage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}